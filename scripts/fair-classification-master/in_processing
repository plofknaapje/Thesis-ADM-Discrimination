import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from fair_classification.loss_funcs import _logistic_loss
from fair_classification.utils import get_correlations, \
    print_covariance_sensitive_attrs,  print_classifier_fairness_stats, \
    train_model, get_line_coordinates, compute_p_rule, add_intercept, \
    split_into_train_test, check_accuracy


def train_test_classifier(data_package: dict, settings: dict) -> tuple:

    w = train_model(data_package, settings)

    _, test_score, _, _ = check_accuracy(
        w, data_package, None, None)

    distances_boundary_test = (np.dot(data_package["x_test"], w)).tolist()

    all_class_labels_assigned_test = np.sign(distances_boundary_test)

    correlation_dict_test = get_correlations(
        None, None, all_class_labels_assigned_test, data_package["x_control_test"],
        settings["sensitive_attrs"])
    cov_dict_test = print_covariance_sensitive_attrs(
        None, data_package["x_test"],
        distances_boundary_test, data_package["x_control_test"],
        settings["sensitive_attrs"])
    p_rule = print_classifier_fairness_stats(
        [test_score],
        [correlation_dict_test],
        [cov_dict_test],
        settings["sensitive_attrs"][0])
    return w, p_rule, test_score


def plot_boundaries(w1, w2, p1, p2, acc1, acc2, fname):
    # we will only draw a small number of points to avoid clutter
    num_to_draw = 200
    x_draw = X[:num_to_draw]
    y_draw = y[:num_to_draw]
    x_control_draw = x_control["nationality"][:num_to_draw]

    X_s_0 = x_draw[x_control_draw == 0.0]
    X_s_1 = x_draw[x_control_draw == 1.0]
    y_s_0 = y_draw[x_control_draw == 0.0]
    y_s_1 = y_draw[x_control_draw == 1.0]
    plt.scatter(X_s_0[y_s_0 == 1.0][:, 1], X_s_0[y_s_0 == 1.0]
                [:, 2], color='green', marker='x', s=30, linewidth=1.5)
    plt.scatter(X_s_0[y_s_0 == -1.0][:, 1], X_s_0[y_s_0 == -1.0]
                [:, 2], color='red', marker='x', s=30, linewidth=1.5)
    plt.scatter(X_s_1[y_s_1 == 1.0][:, 1], X_s_1[y_s_1 == 1.0]
                [:, 2], color='green', marker='o', facecolors='none', s=30)
    plt.scatter(X_s_1[y_s_1 == -1.0][:, 1], X_s_1[y_s_1 == -1.0]
                [:, 2], color='red', marker='o', facecolors='none', s=30)

    x1, x2 = max(x_draw[:, 1]), min(x_draw[:, 1])
    y1, y2 = get_line_coordinates(w1, x1, x2)
    plt.plot([x1, x2], [y1, y2], 'c-', linewidth=3,
             label="Acc=%0.2f; p%% rule=%0.0f%% - Original" % (acc1, p1))
    y1, y2 = get_line_coordinates(w2, x1, x2)
    plt.plot([x1, x2], [y1, y2], 'b--', linewidth=3,
             label="Acc=%0.2f; p%% rule=%0.0f%% - Constrained" % (acc2, p2))

    # dont need the ticks to see the data distribution
    plt.tick_params(axis='x', which='both', bottom='off',
                    top='off', labelbottom='off')
    plt.tick_params(axis='y', which='both', left='off',
                    right='off', labelleft='off')
    plt.legend(loc=2, fontsize=15)
    plt.xlim((-15, 10))
    plt.ylim((-10, 15))
    plt.savefig(fname)
    plt.show()


def selective_pred_sum(predictions, x_control, nationality, outcome):
    return sum(x_control["nationality"][i] == nationality and predictions[i] == outcome
               for i in range(len(predictions)))


def preprocessing_X(df, intercept=True):
    X = df.loc[:, ["test_score", "english_cert", "extracurricular"]]
    X["english_cert"] = X["english_cert"].astype(int)
    X["extracurricular"] = X["extracurricular"].astype(int)
    if intercept:
        return add_intercept(X.to_numpy())
    else:
        return X.to_numpy()


if __name__ == '__main__':

    mapping_nat = {"Non_Dutch": "0", "Dutch": "1"}
    mapping_acc = {"True": "1", "False": "-1"}
    df = pd.read_csv("../../data/selection.csv").sample(frac=1)
    df_test = pd.read_csv("../../data/selection_test.csv")
    df = pd.concat([df, df_test])

    y = np.array(df["accepted"].astype(str).replace(mapping_acc).astype(int))
    X = preprocessing_X(df, intercept=True)
    x_control = {"nationality": np.array(df["nationality"].replace(mapping_nat).astype(int))}

    X_test = preprocessing_X(df_test, intercept=True)
    x_test_control = {"nationality": np.array(df_test["nationality"].replace(mapping_nat).astype(int))}

    # print(X, type(X))
    # print(y, type(y))
    # print(x_control)

    compute_p_rule(x_control["nationality"], y)

    # Split the data into train and test
    data_package = {}
    names = ["x_train", "y_train", "x_control_train",
             "x_test", "y_test", "x_control_test"]

    train_fold_size = 0.5  # Train with the train data and test with the test data
    data = split_into_train_test(X, y, x_control, train_fold_size)
    for i in range(6):
        data_package[names[i]] = data[i]

    settings = {"fairness": None, "accuracy": None, "sep_constraint": None,
                "loss_function": _logistic_loss,
                "sensitive_attrs": ["nationality"],
                "sensitive_attrs_to_cov_thresh": {},
                "gamma": None}

    """ Classify the data while optimizing for accuracy """
    print()
    print("== Unconstrained (original) classifier ==")
    # all constraint flags are set to 0 since we want to train an
    # unconstrained (original) classifier
    settings_def = settings.copy()
    settings_def["fairness"] = 0
    settings_def["accuracy"] = 0
    settings_def["sep_constraint"] = 0

    w_uncons, p_uncons, acc_uncons = train_test_classifier(
        data_package=data_package, settings=settings_def
    )

    """ Group Fairness """
    print(w_uncons)
    predictions = np.sign(np.dot(X_test, w_uncons).tolist())
    outcomes = {
        "Dutch_Pos": selective_pred_sum(predictions, x_test_control, 1, 1),
        "Non_Dutch_Pos": selective_pred_sum(predictions, x_test_control, 0, 1),
        "Dutch_Neg": selective_pred_sum(predictions, x_test_control, 1, -1),
        "Non_Dutch_Neg": selective_pred_sum(predictions, x_test_control, 0, -1)
    }

    print(outcomes)
    print("Dutch: {0:.1f}%".format(outcomes["Dutch_Pos"]/(outcomes["Dutch_Pos"] + outcomes["Dutch_Neg"])*100))
    print(
        "Non-Dutch: {0:.1f}%".format(outcomes["Non_Dutch_Pos"]/(outcomes["Non_Dutch_Pos"] + outcomes["Non_Dutch_Neg"])*100))

    """
    ########
    Optimize for accuracy while achieving perfect fairness """
    settings_fair = settings.copy()
    settings_fair["fairness"] = 1
    settings_fair["accuracy"] = 0
    settings_fair["sep_constraint"] = 0
    settings_fair["sensitive_attrs_to_cov_thresh"] = {"nationality": 0}

    print()
    print("== Classifier with fairness constraint ==")
    w_f_cons, p_f_cons, acc_f_cons = train_test_classifier(
        data_package, settings_fair
    )

    print(w_f_cons)
    predictions = np.sign(np.dot(X_test, w_f_cons).tolist())
    outcomes = {
        "Dutch_Pos": selective_pred_sum(predictions, x_test_control, 1, 1),
        "Non_Dutch_Pos": selective_pred_sum(predictions, x_test_control, 0, 1),
        "Dutch_Neg": selective_pred_sum(predictions, x_test_control, 1, -1),
        "Non_Dutch_Neg": selective_pred_sum(predictions, x_test_control, 0, -1)
    }

    print(outcomes)
    print("Dutch: {0:.1f}%".format(outcomes["Dutch_Pos"]/(outcomes["Dutch_Pos"] + outcomes["Dutch_Neg"])*100))
    print(
        "Non-Dutch: {0:.1f}%".format(outcomes["Non_Dutch_Pos"]/(outcomes["Non_Dutch_Pos"] + outcomes["Non_Dutch_Neg"])*100))
    # plot_boundaries(w_uncons, w_f_cons, p_uncons, p_f_cons,
    #                 acc_uncons, acc_f_cons, "img/f_cons.png")
